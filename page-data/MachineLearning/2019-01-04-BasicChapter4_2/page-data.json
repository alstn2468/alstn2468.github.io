{"componentChunkName":"component---src-templates-blog-post-js","path":"/MachineLearning/2019-01-04-BasicChapter4_2","result":{"data":{"site":{"siteMetadata":{"title":"Minsu's Dev Log","author":"Minsu Kim","siteUrl":"https://alstn2468.github.io","comment":{"disqusShortName":"","utterances":"alstn2468/alstn2468.github.io"},"sponsor":{"buyMeACoffeeId":"eMLdEwU"}}},"markdownRemark":{"id":"02c6bb8f-2228-52c9-9808-fc6710eb8856","excerpt":"해당 게시물은 Edwith에서 제공하는\n머신러닝과 딥러닝 BASIC을 듣고 요약 정리한 글입니다. Simplified hypothesis Gradient descent Output when W = 5 경사하강법이 잘 되는지 테스트 오른쪽에서 하강 Output when W = -3 경사하강법이 잘 되는지 테스트 왼쪽에서 하강 Optional : computegradient and applygradient Gradient…","html":"<p>해당 게시물은 <a href=\"https://www.edwith.org\">Edwith</a>에서 제공하는<br/>\n<a href=\"https://www.edwith.org/others26/joinLectures/9829\">머신러닝과 딥러닝 BASIC</a>을 듣고 요약 정리한 글입니다.</p>\n<h2 id=\"simplified-hypothesis\" style=\"position:relative;\"><a href=\"#simplified-hypothesis\" aria-label=\"simplified hypothesis permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Simplified hypothesis</h2>\n<span class=\"katex-display\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\" display=\"block\"><semantics><mrow><mi>H</mi><mo stretchy=\"false\">(</mo><mi>x</mi><mo stretchy=\"false\">)</mo><mo>=</mo><mi>W</mi><mi>x</mi></mrow><annotation encoding=\"application/x-tex\">H(x) = Wx</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.08125em;\">H</span><span class=\"mopen\">(</span><span class=\"mord mathnormal\">x</span><span class=\"mclose\">)</span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.6833em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.13889em;\">W</span><span class=\"mord mathnormal\">x</span></span></span></span></span>\n<span class=\"katex-display\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\" display=\"block\"><semantics><mrow><mi>c</mi><mi>o</mi><mi>s</mi><mi>t</mi><mo stretchy=\"false\">(</mo><mi>W</mi><mo stretchy=\"false\">)</mo><mo>=</mo><mfrac><mn>1</mn><mi>m</mi></mfrac><mo>∑</mo><mi mathvariant=\"normal\">_</mi><msup><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>m</mi></msup><mo stretchy=\"false\">(</mo><mi>W</mi><msup><mi>x</mi><mrow><mo stretchy=\"false\">(</mo><mi>i</mi><mo stretchy=\"false\">)</mo></mrow></msup><mo>−</mo><msup><mi>y</mi><mrow><mo stretchy=\"false\">(</mo><mi>i</mi><mo stretchy=\"false\">)</mo></mrow></msup><msup><mo stretchy=\"false\">)</mo><mn>2</mn></msup></mrow><annotation encoding=\"application/x-tex\">cost(W) = \\dfrac{1}{m}\\sum\\_{i=1}^m(Wx^{(i)} - y^{(i)})^2</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord mathnormal\">cos</span><span class=\"mord mathnormal\">t</span><span class=\"mopen\">(</span><span class=\"mord mathnormal\" style=\"margin-right:0.13889em;\">W</span><span class=\"mclose\">)</span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:2.0074em;vertical-align:-0.686em;\"></span><span class=\"mord\"><span class=\"mopen nulldelimiter\"></span><span class=\"mfrac\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:1.3214em;\"><span style=\"top:-2.314em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\">m</span></span></span><span style=\"top:-3.23em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"frac-line\" style=\"border-bottom-width:0.04em;\"></span></span><span style=\"top:-3.677em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord\">1</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.686em;\"><span></span></span></span></span></span><span class=\"mclose nulldelimiter\"></span></span><span class=\"mspace\" style=\"margin-right:0.1667em;\"></span><span class=\"mop op-symbol large-op\" style=\"position:relative;top:0em;\">∑</span><span class=\"mspace\" style=\"margin-right:0.1667em;\"></span><span class=\"mord\" style=\"margin-right:0.02778em;\">_</span><span class=\"mord\"><span class=\"mord\"><span class=\"mord mathnormal\">i</span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span><span class=\"mord\">1</span></span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.7144em;\"><span style=\"top:-3.113em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\">m</span></span></span></span></span></span></span></span><span class=\"mopen\">(</span><span class=\"mord mathnormal\" style=\"margin-right:0.13889em;\">W</span><span class=\"mord\"><span class=\"mord mathnormal\">x</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.938em;\"><span style=\"top:-3.113em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mopen mtight\">(</span><span class=\"mord mathnormal mtight\">i</span><span class=\"mclose mtight\">)</span></span></span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2222em;\"></span><span class=\"mbin\">−</span><span class=\"mspace\" style=\"margin-right:0.2222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1.188em;vertical-align:-0.25em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.03588em;\">y</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.938em;\"><span style=\"top:-3.113em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mopen mtight\">(</span><span class=\"mord mathnormal mtight\">i</span><span class=\"mclose mtight\">)</span></span></span></span></span></span></span></span></span><span class=\"mclose\"><span class=\"mclose\">)</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.8641em;\"><span style=\"top:-3.113em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">2</span></span></span></span></span></span></span></span></span></span></span></span>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token keyword\">import</span> tensorflow <span class=\"token keyword\">as</span> tf\n<span class=\"token keyword\">import</span> matplotlib<span class=\"token punctuation\">.</span>pyplot <span class=\"token keyword\">as</span> plt\n\nX <span class=\"token operator\">=</span> <span class=\"token punctuation\">[</span><span class=\"token number\">1</span><span class=\"token punctuation\">,</span> <span class=\"token number\">2</span><span class=\"token punctuation\">,</span> <span class=\"token number\">3</span><span class=\"token punctuation\">]</span>\nY <span class=\"token operator\">=</span> <span class=\"token punctuation\">[</span><span class=\"token number\">1</span><span class=\"token punctuation\">,</span> <span class=\"token number\">2</span><span class=\"token punctuation\">,</span> <span class=\"token number\">3</span><span class=\"token punctuation\">]</span>\n\nW <span class=\"token operator\">=</span> tf<span class=\"token punctuation\">.</span>placeholder<span class=\"token punctuation\">(</span>tf<span class=\"token punctuation\">.</span>float32<span class=\"token punctuation\">)</span>\n\n<span class=\"token comment\"># Our hypothesis for linear model X * W</span>\nhypothesis <span class=\"token operator\">=</span> X <span class=\"token operator\">*</span> W\n\n<span class=\"token comment\"># cost/loss function</span>\ncost <span class=\"token operator\">=</span> tf<span class=\"token punctuation\">.</span>reduce_mean<span class=\"token punctuation\">(</span>tf<span class=\"token punctuation\">.</span>square<span class=\"token punctuation\">(</span>hypothesis <span class=\"token operator\">-</span> Y<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n\n<span class=\"token comment\"># Launch the graph in a session</span>\nsess <span class=\"token operator\">=</span> tf<span class=\"token punctuation\">.</span>Session<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n\n<span class=\"token comment\"># Variables for plotting cost function</span>\nW_history <span class=\"token operator\">=</span> <span class=\"token punctuation\">[</span><span class=\"token punctuation\">]</span>\ncost_history <span class=\"token operator\">=</span> <span class=\"token punctuation\">[</span><span class=\"token punctuation\">]</span>\n\n<span class=\"token keyword\">for</span> i <span class=\"token keyword\">in</span> <span class=\"token builtin\">range</span><span class=\"token punctuation\">(</span><span class=\"token operator\">-</span><span class=\"token number\">30</span><span class=\"token punctuation\">,</span> <span class=\"token number\">50</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n    curr_W <span class=\"token operator\">=</span> i <span class=\"token operator\">*</span> <span class=\"token number\">0.1</span>\n    curr_cost <span class=\"token operator\">=</span> sess<span class=\"token punctuation\">.</span>run<span class=\"token punctuation\">(</span>cost<span class=\"token punctuation\">,</span> feed_dict<span class=\"token operator\">=</span><span class=\"token punctuation\">{</span>W<span class=\"token punctuation\">:</span> curr_W<span class=\"token punctuation\">}</span><span class=\"token punctuation\">)</span>\n    W_history<span class=\"token punctuation\">.</span>append<span class=\"token punctuation\">(</span>curr_W<span class=\"token punctuation\">)</span>\n    cost_history<span class=\"token punctuation\">.</span>append<span class=\"token punctuation\">(</span>curr_cost<span class=\"token punctuation\">)</span>\n\n<span class=\"token comment\"># Show the cost function</span>\nplt<span class=\"token punctuation\">.</span>plot<span class=\"token punctuation\">(</span>W_history<span class=\"token punctuation\">,</span> cost_history<span class=\"token punctuation\">)</span>\nplt<span class=\"token punctuation\">.</span>show<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span></code></pre></div>\n<span class=\"gatsby-resp-image-wrapper\" style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 372px; \">\n      <span class=\"gatsby-resp-image-background-image\" style=\"padding-bottom: 68%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAOCAYAAAAvxDzwAAAACXBIWXMAAAsSAAALEgHS3X78AAAB0klEQVQ4y51TzW7TQBBe/l6C1+DAKwDtgRPvUS4o6glxy7tAVdNcCCEoqYiIcuUQUvdHikiyths7TWLvztrTGdfbulaJ1I40/ta7M99+I38WR677/OT0rOZ5cmcymb6fTh+UO74nP/R6vZei87P9Vs4XmGjA1BgEMGjM/RIAcK00DofDT+L3r8PX0SrGKIYEEeEhGWujwhjw9MStiWazua21Rn+pTJpmGRVk9wmu9y8SA2mGx+7Rrvjeam0bkrxMjInWGvGKETcFn9saBSkyIa//jka7otPpvGGFFEYu4uvCclOVrIzBUiGNnBOOmLBFClVBuIg1VlVuIlX0AUld3ntN2G63t6xCfshFgibN7iStokdk2qSbCRNt8sLq2FXkacKVsnu3CZXKD4wtDmnssDR6Oe2lPEnp/Iaw2+2+KggVHQAneyu4SIAUlPx2tb9WAFMyLVks32MySlUQ1kS/399ip98V7IZgpTGBDMkdOCfV8zX8106u634UjUbjxXg8/hGG4Rcp5dcgCPY9z3N833fm54EzmUlnePZv/8/x2JnIYI/++YMoCvdms9kB9Vj8TD3fBoPBO1Gv1wXFU7qA8XGBjxiLtbDr4v1Jgbbnme3lxyV/Juywe5cSqAAAAABJRU5ErkJggg=='); background-size: cover; display: block;\"></span>\n  <img class=\"gatsby-resp-image-image\" alt=\"1\" title=\"1\" src=\"/static/b038655610e845fdfb3b3c0d68ea6e7f/98b6e/1.png\" srcset=\"/static/b038655610e845fdfb3b3c0d68ea6e7f/8a4e8/1.png 150w,\n/static/b038655610e845fdfb3b3c0d68ea6e7f/5a46d/1.png 300w,\n/static/b038655610e845fdfb3b3c0d68ea6e7f/98b6e/1.png 372w\" sizes=\"(max-width: 372px) 100vw, 372px\" style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\" loading=\"lazy\">\n    </span>\n<h2 id=\"gradient-descent\" style=\"position:relative;\"><a href=\"#gradient-descent\" aria-label=\"gradient descent permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Gradient descent</h2>\n<span class=\"katex-display\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\" display=\"block\"><semantics><mrow><mi>W</mi><mo>:</mo><mo>=</mo><mi>W</mi><mo>−</mo><mi>a</mi><mfrac><mn>1</mn><mi>m</mi></mfrac><mo>∑</mo><mi mathvariant=\"normal\">_</mi><msup><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>m</mi></msup><mo stretchy=\"false\">(</mo><mi>W</mi><msup><mi>x</mi><mrow><mo stretchy=\"false\">(</mo><mi>i</mi><mo stretchy=\"false\">)</mo></mrow></msup><mo>−</mo><msup><mi>y</mi><mrow><mo stretchy=\"false\">(</mo><mi>i</mi><mo stretchy=\"false\">)</mo></mrow></msup><mo stretchy=\"false\">)</mo><msup><mi>x</mi><mrow><mo stretchy=\"false\">(</mo><mi>i</mi><mo stretchy=\"false\">)</mo></mrow></msup></mrow><annotation encoding=\"application/x-tex\">W := W - a\\dfrac{1}{m}\\sum\\_{i=1}^m(Wx^{(i)} - y^{(i)})x^{(i)}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.6833em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.13889em;\">W</span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span><span class=\"mrel\">:=</span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.7667em;vertical-align:-0.0833em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.13889em;\">W</span><span class=\"mspace\" style=\"margin-right:0.2222em;\"></span><span class=\"mbin\">−</span><span class=\"mspace\" style=\"margin-right:0.2222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:2.0074em;vertical-align:-0.686em;\"></span><span class=\"mord mathnormal\">a</span><span class=\"mord\"><span class=\"mopen nulldelimiter\"></span><span class=\"mfrac\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:1.3214em;\"><span style=\"top:-2.314em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\">m</span></span></span><span style=\"top:-3.23em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"frac-line\" style=\"border-bottom-width:0.04em;\"></span></span><span style=\"top:-3.677em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord\">1</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.686em;\"><span></span></span></span></span></span><span class=\"mclose nulldelimiter\"></span></span><span class=\"mspace\" style=\"margin-right:0.1667em;\"></span><span class=\"mop op-symbol large-op\" style=\"position:relative;top:0em;\">∑</span><span class=\"mspace\" style=\"margin-right:0.1667em;\"></span><span class=\"mord\" style=\"margin-right:0.02778em;\">_</span><span class=\"mord\"><span class=\"mord\"><span class=\"mord mathnormal\">i</span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span><span class=\"mord\">1</span></span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.7144em;\"><span style=\"top:-3.113em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\">m</span></span></span></span></span></span></span></span><span class=\"mopen\">(</span><span class=\"mord mathnormal\" style=\"margin-right:0.13889em;\">W</span><span class=\"mord\"><span class=\"mord mathnormal\">x</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.938em;\"><span style=\"top:-3.113em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mopen mtight\">(</span><span class=\"mord mathnormal mtight\">i</span><span class=\"mclose mtight\">)</span></span></span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2222em;\"></span><span class=\"mbin\">−</span><span class=\"mspace\" style=\"margin-right:0.2222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1.188em;vertical-align:-0.25em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.03588em;\">y</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.938em;\"><span style=\"top:-3.113em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mopen mtight\">(</span><span class=\"mord mathnormal mtight\">i</span><span class=\"mclose mtight\">)</span></span></span></span></span></span></span></span></span><span class=\"mclose\">)</span><span class=\"mord\"><span class=\"mord mathnormal\">x</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.938em;\"><span style=\"top:-3.113em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mopen mtight\">(</span><span class=\"mord mathnormal mtight\">i</span><span class=\"mclose mtight\">)</span></span></span></span></span></span></span></span></span></span></span></span></span>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token keyword\">import</span> tensorflow <span class=\"token keyword\">as</span> tf\n\nx_data <span class=\"token operator\">=</span> <span class=\"token punctuation\">[</span><span class=\"token number\">1</span><span class=\"token punctuation\">,</span> <span class=\"token number\">2</span><span class=\"token punctuation\">,</span> <span class=\"token number\">3</span><span class=\"token punctuation\">]</span>\ny_data <span class=\"token operator\">=</span> <span class=\"token punctuation\">[</span><span class=\"token number\">1</span><span class=\"token punctuation\">,</span> <span class=\"token number\">2</span><span class=\"token punctuation\">,</span> <span class=\"token number\">3</span><span class=\"token punctuation\">]</span>\n\nW <span class=\"token operator\">=</span> tf<span class=\"token punctuation\">.</span>Variable<span class=\"token punctuation\">(</span>tf<span class=\"token punctuation\">.</span>random_normal<span class=\"token punctuation\">(</span><span class=\"token punctuation\">[</span><span class=\"token number\">1</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span> name<span class=\"token operator\">=</span><span class=\"token string\">'weight'</span><span class=\"token punctuation\">)</span>\n\nX <span class=\"token operator\">=</span> tf<span class=\"token punctuation\">.</span>placeholder<span class=\"token punctuation\">(</span>tf<span class=\"token punctuation\">.</span>float32<span class=\"token punctuation\">)</span>\nY <span class=\"token operator\">=</span> tf<span class=\"token punctuation\">.</span>placeholder<span class=\"token punctuation\">(</span>tf<span class=\"token punctuation\">.</span>float32<span class=\"token punctuation\">)</span>\n\n<span class=\"token comment\"># Our hypothesis for linear model X * W</span>\nhypothesis <span class=\"token operator\">=</span> X <span class=\"token operator\">*</span> W\n\n<span class=\"token comment\"># cost/loss function</span>\ncost <span class=\"token operator\">=</span> tf<span class=\"token punctuation\">.</span>reduce_mean<span class=\"token punctuation\">(</span>tf<span class=\"token punctuation\">.</span>square<span class=\"token punctuation\">(</span>hypothesis <span class=\"token operator\">-</span> Y<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n\n<span class=\"token comment\"># Minimize : Gradient Descent using derivative</span>\n<span class=\"token comment\"># W -= learning_rate * derivative</span>\nlearning_rate <span class=\"token operator\">=</span> <span class=\"token number\">0.1</span>\ngradient <span class=\"token operator\">=</span> tf<span class=\"token punctuation\">.</span>reduce_mean<span class=\"token punctuation\">(</span><span class=\"token punctuation\">(</span>W <span class=\"token operator\">*</span> X <span class=\"token operator\">-</span> Y<span class=\"token punctuation\">)</span> <span class=\"token operator\">*</span> X<span class=\"token punctuation\">)</span>\ndescent <span class=\"token operator\">=</span> W <span class=\"token operator\">-</span> learning_rate <span class=\"token operator\">*</span> gradient\nupdate <span class=\"token operator\">=</span> W<span class=\"token punctuation\">.</span>assign<span class=\"token punctuation\">(</span>descent<span class=\"token punctuation\">)</span>\n\n<span class=\"token comment\"># Launch the graph in a session.</span>\nsess <span class=\"token operator\">=</span> tf<span class=\"token punctuation\">.</span>Session<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n\n<span class=\"token comment\"># Initializes global variables in the graph.</span>\nsess<span class=\"token punctuation\">.</span>run<span class=\"token punctuation\">(</span>tf<span class=\"token punctuation\">.</span>global_variables_initializer<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n\n<span class=\"token keyword\">for</span> step <span class=\"token keyword\">in</span> <span class=\"token builtin\">range</span><span class=\"token punctuation\">(</span><span class=\"token number\">21</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n    sess<span class=\"token punctuation\">.</span>run<span class=\"token punctuation\">(</span>update<span class=\"token punctuation\">,</span> feed_dict<span class=\"token operator\">=</span><span class=\"token punctuation\">{</span>X<span class=\"token punctuation\">:</span> x_data<span class=\"token punctuation\">,</span> Y<span class=\"token punctuation\">:</span> y_data<span class=\"token punctuation\">}</span><span class=\"token punctuation\">)</span>\n    <span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span>step<span class=\"token punctuation\">,</span> sess<span class=\"token punctuation\">.</span>run<span class=\"token punctuation\">(</span>cost<span class=\"token punctuation\">,</span> feed_dict<span class=\"token operator\">=</span><span class=\"token punctuation\">{</span>X<span class=\"token punctuation\">:</span> x_data<span class=\"token punctuation\">,</span> Y<span class=\"token punctuation\">:</span> y_data<span class=\"token punctuation\">}</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span> sess<span class=\"token punctuation\">.</span>run<span class=\"token punctuation\">(</span>W<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span></code></pre></div>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">0 12.285609 [-0.6225382]\n1 3.4945729 [0.13464624]\n2 0.99401206 [0.53847796]\n3 0.28274122 [0.75385493]\n4 0.08042419 [0.8687226]\n5 0.02287622 [0.9299854]\n6 0.0065070093 [0.9626589]\n7 0.0018508838 [0.9800847]\n8 0.00052647345 [0.9893785]\n9 0.00014975447 [0.9943352]\n10 4.2596832e-05 [0.99697876]\n11 1.2117175e-05 [0.99838865]\n12 3.4466948e-06 [0.9991406]\n13 9.802366e-07 [0.9995417]\n14 2.7886367e-07 [0.99975556]\n15 7.9282884e-08 [0.99986964]\n16 2.2523963e-08 [0.9999305]\n17 6.4054433e-09 [0.9999629]\n18 1.8274401e-09 [0.9999802]\n19 5.2067267e-10 [0.99998945]\n20 1.4516388e-10 [0.9999944]</code></pre></div>\n<h2 id=\"output-when-w--5\" style=\"position:relative;\"><a href=\"#output-when-w--5\" aria-label=\"output when w  5 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Output when W = 5</h2>\n<ul>\n<li><strong>경사하강법</strong>이 잘 되는지 테스트</li>\n<li>오른쪽에서 하강</li>\n</ul>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token keyword\">import</span> tensorflow <span class=\"token keyword\">as</span> tf\n\n<span class=\"token comment\"># tf Graph Input</span>\nX <span class=\"token operator\">=</span> <span class=\"token punctuation\">[</span><span class=\"token number\">1</span><span class=\"token punctuation\">,</span> <span class=\"token number\">2</span><span class=\"token punctuation\">,</span> <span class=\"token number\">3</span><span class=\"token punctuation\">]</span>\nY <span class=\"token operator\">=</span> <span class=\"token punctuation\">[</span><span class=\"token number\">1</span><span class=\"token punctuation\">,</span> <span class=\"token number\">2</span><span class=\"token punctuation\">,</span> <span class=\"token number\">3</span><span class=\"token punctuation\">]</span>\n\n<span class=\"token comment\"># Set wrong model weights</span>\nW <span class=\"token operator\">=</span> tf<span class=\"token punctuation\">.</span>Variable<span class=\"token punctuation\">(</span><span class=\"token number\">5.0</span><span class=\"token punctuation\">)</span>\n\n<span class=\"token comment\"># Linear model</span>\nhypothesis <span class=\"token operator\">=</span> X <span class=\"token operator\">*</span> W\n\n<span class=\"token comment\"># cost/Loss function</span>\ncost <span class=\"token operator\">=</span> tf<span class=\"token punctuation\">.</span>reduce_mean<span class=\"token punctuation\">(</span>tf<span class=\"token punctuation\">.</span>square<span class=\"token punctuation\">(</span>hypothesis <span class=\"token operator\">-</span> Y<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n\n<span class=\"token comment\"># Minimize : Gradient Descent Magic</span>\noptimizer <span class=\"token operator\">=</span> tf<span class=\"token punctuation\">.</span>train<span class=\"token punctuation\">.</span>GradientDescentOptimizer<span class=\"token punctuation\">(</span>learning_rate<span class=\"token operator\">=</span><span class=\"token number\">0.1</span><span class=\"token punctuation\">)</span>\ntrain <span class=\"token operator\">=</span> optimizer<span class=\"token punctuation\">.</span>minimize<span class=\"token punctuation\">(</span>cost<span class=\"token punctuation\">)</span>\n\n<span class=\"token comment\"># Launch the graph in a session</span>\nsess <span class=\"token operator\">=</span> tf<span class=\"token punctuation\">.</span>Session<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n\n<span class=\"token comment\"># Initializes global variables int he graph</span>\nsess<span class=\"token punctuation\">.</span>run<span class=\"token punctuation\">(</span>tf<span class=\"token punctuation\">.</span>global_variables_initializer<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n\n<span class=\"token keyword\">for</span> step <span class=\"token keyword\">in</span> <span class=\"token builtin\">range</span><span class=\"token punctuation\">(</span><span class=\"token number\">100</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n    <span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span>step<span class=\"token punctuation\">,</span> sess<span class=\"token punctuation\">.</span>run<span class=\"token punctuation\">(</span>W<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n    sess<span class=\"token punctuation\">.</span>run<span class=\"token punctuation\">(</span>train<span class=\"token punctuation\">)</span></code></pre></div>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">0 5.0\n1 1.2666664\n2 1.0177778\n3 1.0011852\n4 1.000079\n5 1.0000052\n6 1.0000004\n7 1.0\n8 1.0\n9 1.0\n10 1.0\n...\n90 1.0\n91 1.0\n92 1.0\n93 1.0\n94 1.0\n95 1.0\n96 1.0\n97 1.0\n98 1.0\n99 1.0</code></pre></div>\n<h2 id=\"output-when-w---3\" style=\"position:relative;\"><a href=\"#output-when-w---3\" aria-label=\"output when w   3 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Output when W = -3</h2>\n<ul>\n<li><strong>경사하강법</strong>이 잘 되는지 테스트</li>\n<li>왼쪽에서 하강</li>\n</ul>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token keyword\">import</span> tensorflow <span class=\"token keyword\">as</span> tf\n\n<span class=\"token comment\"># tf Graph Input</span>\nX <span class=\"token operator\">=</span> <span class=\"token punctuation\">[</span><span class=\"token number\">1</span><span class=\"token punctuation\">,</span> <span class=\"token number\">2</span><span class=\"token punctuation\">,</span> <span class=\"token number\">3</span><span class=\"token punctuation\">]</span>\nY <span class=\"token operator\">=</span> <span class=\"token punctuation\">[</span><span class=\"token number\">1</span><span class=\"token punctuation\">,</span> <span class=\"token number\">2</span><span class=\"token punctuation\">,</span> <span class=\"token number\">3</span><span class=\"token punctuation\">]</span>\n\n<span class=\"token comment\"># Set wrong model weights</span>\nW <span class=\"token operator\">=</span> tf<span class=\"token punctuation\">.</span>Variable<span class=\"token punctuation\">(</span><span class=\"token operator\">-</span><span class=\"token number\">3.0</span><span class=\"token punctuation\">)</span>\n\n<span class=\"token comment\"># Linear model</span>\nhypothesis <span class=\"token operator\">=</span> X <span class=\"token operator\">*</span> W\n\n<span class=\"token comment\"># cost/Loss function</span>\ncost <span class=\"token operator\">=</span> tf<span class=\"token punctuation\">.</span>reduce_mean<span class=\"token punctuation\">(</span>tf<span class=\"token punctuation\">.</span>square<span class=\"token punctuation\">(</span>hypothesis <span class=\"token operator\">-</span> Y<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n\n<span class=\"token comment\"># Minimize : Gradient Descent Magic</span>\noptimizer <span class=\"token operator\">=</span> tf<span class=\"token punctuation\">.</span>train<span class=\"token punctuation\">.</span>GradientDescentOptimizer<span class=\"token punctuation\">(</span>learning_rate<span class=\"token operator\">=</span><span class=\"token number\">0.1</span><span class=\"token punctuation\">)</span>\ntrain <span class=\"token operator\">=</span> optimizer<span class=\"token punctuation\">.</span>minimize<span class=\"token punctuation\">(</span>cost<span class=\"token punctuation\">)</span>\n\n<span class=\"token comment\"># Launch the graph in a session</span>\nsess <span class=\"token operator\">=</span> tf<span class=\"token punctuation\">.</span>Session<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n\n<span class=\"token comment\"># Initializes global variables int he graph</span>\nsess<span class=\"token punctuation\">.</span>run<span class=\"token punctuation\">(</span>tf<span class=\"token punctuation\">.</span>global_variables_initializer<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n\n<span class=\"token keyword\">for</span> step <span class=\"token keyword\">in</span> <span class=\"token builtin\">range</span><span class=\"token punctuation\">(</span><span class=\"token number\">100</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n    <span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span>step<span class=\"token punctuation\">,</span> sess<span class=\"token punctuation\">.</span>run<span class=\"token punctuation\">(</span>W<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n    sess<span class=\"token punctuation\">.</span>run<span class=\"token punctuation\">(</span>train<span class=\"token punctuation\">)</span></code></pre></div>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">0 -3.0\n1 0.7333336\n2 0.98222226\n3 0.9988148\n4 0.99992096\n5 0.9999947\n6 0.99999964\n7 0.99999994\n8 1.0\n9 1.0\n10 1.0\n...\n90 1.0\n91 1.0\n92 1.0\n93 1.0\n94 1.0\n95 1.0\n96 1.0\n97 1.0\n98 1.0\n99 1.0</code></pre></div>\n<h2 id=\"optional--computegradient-and-applygradient\" style=\"position:relative;\"><a href=\"#optional--computegradient-and-applygradient\" aria-label=\"optional  computegradient and applygradient permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Optional : compute<em>gradient and apply</em>gradient</h2>\n<ul>\n<li>Gradient를 수정하고 싶을 때 사용</li>\n<li><code class=\"language-text\">compute_gradients()</code>함수를 사용해 <code class=\"language-text\">cost</code>에 알맞는 <code class=\"language-text\">gradient</code> 계산</li>\n<li>계산한 <code class=\"language-text\">gradient</code>를 <code class=\"language-text\">apply_gradients()</code>함수 사용으로 <code class=\"language-text\">gradient</code> 적용</li>\n</ul>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token keyword\">import</span> tensorflow <span class=\"token keyword\">as</span> tf\n\n<span class=\"token comment\"># tf Graph Input</span>\nX <span class=\"token operator\">=</span> <span class=\"token punctuation\">[</span><span class=\"token number\">1</span><span class=\"token punctuation\">,</span> <span class=\"token number\">2</span><span class=\"token punctuation\">,</span> <span class=\"token number\">3</span><span class=\"token punctuation\">]</span>\nY <span class=\"token operator\">=</span> <span class=\"token punctuation\">[</span><span class=\"token number\">1</span><span class=\"token punctuation\">,</span> <span class=\"token number\">2</span><span class=\"token punctuation\">,</span> <span class=\"token number\">3</span><span class=\"token punctuation\">]</span>\n\n<span class=\"token comment\"># Set wrong model weights</span>\nW <span class=\"token operator\">=</span> tf<span class=\"token punctuation\">.</span>Variable<span class=\"token punctuation\">(</span><span class=\"token number\">5.</span><span class=\"token punctuation\">)</span>\n\n<span class=\"token comment\"># Linear model</span>\nhypothesis <span class=\"token operator\">=</span> X <span class=\"token operator\">*</span> W\n\n<span class=\"token comment\"># Manual gradient</span>\ngradient <span class=\"token operator\">=</span> tf<span class=\"token punctuation\">.</span>reduce_mean<span class=\"token punctuation\">(</span><span class=\"token punctuation\">(</span>W <span class=\"token operator\">*</span> X <span class=\"token operator\">-</span> Y<span class=\"token punctuation\">)</span> <span class=\"token operator\">*</span> X<span class=\"token punctuation\">)</span> <span class=\"token operator\">*</span> <span class=\"token number\">2</span>\n\n<span class=\"token comment\"># cost/Loss function</span>\ncost <span class=\"token operator\">=</span> tf<span class=\"token punctuation\">.</span>reduce_mean<span class=\"token punctuation\">(</span>tf<span class=\"token punctuation\">.</span>square<span class=\"token punctuation\">(</span>hypothesis <span class=\"token operator\">-</span> Y<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n<span class=\"token comment\"># Minimize : Gradient Descent Magic</span>\noptimizer <span class=\"token operator\">=</span> tf<span class=\"token punctuation\">.</span>train<span class=\"token punctuation\">.</span>GradientDescentOptimizer<span class=\"token punctuation\">(</span>learning_rate<span class=\"token operator\">=</span><span class=\"token number\">0.1</span><span class=\"token punctuation\">)</span>\n\n<span class=\"token comment\"># Get gradients</span>\ngvs <span class=\"token operator\">=</span> optimizer<span class=\"token punctuation\">.</span>compute_gradients<span class=\"token punctuation\">(</span>cost<span class=\"token punctuation\">,</span> <span class=\"token punctuation\">[</span>W<span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span>\n<span class=\"token comment\"># Apply gradients</span>\napply_gradients <span class=\"token operator\">=</span> optimizer<span class=\"token punctuation\">.</span>apply_gradients<span class=\"token punctuation\">(</span>gvs<span class=\"token punctuation\">)</span>\n\n<span class=\"token comment\"># Launch the graph in a session</span>\nsess <span class=\"token operator\">=</span> tf<span class=\"token punctuation\">.</span>Session<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n\n<span class=\"token comment\"># Initializes global variables int he graph</span>\nsess<span class=\"token punctuation\">.</span>run<span class=\"token punctuation\">(</span>tf<span class=\"token punctuation\">.</span>global_variables_initializer<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n\n<span class=\"token keyword\">for</span> step <span class=\"token keyword\">in</span> <span class=\"token builtin\">range</span><span class=\"token punctuation\">(</span><span class=\"token number\">100</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n    <span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span>step<span class=\"token punctuation\">,</span> sess<span class=\"token punctuation\">.</span>run<span class=\"token punctuation\">(</span><span class=\"token punctuation\">[</span>gradient<span class=\"token punctuation\">,</span> W<span class=\"token punctuation\">,</span> gvs<span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n    sess<span class=\"token punctuation\">.</span>run<span class=\"token punctuation\">(</span>apply_gradients<span class=\"token punctuation\">)</span></code></pre></div>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">0 [37.333332, 5.0, [(37.333336, 5.0)]]\n1 [2.4888866, 1.2666664, [(2.4888866, 1.2666664)]]\n2 [0.1659259, 1.0177778, [(0.1659259, 1.0177778)]]\n3 [0.011061668, 1.0011852, [(0.011061668, 1.0011852)]]\n4 [0.00073742867, 1.000079, [(0.00073742867, 1.000079)]]\n5 [4.895528e-05, 1.0000052, [(4.8955284e-05, 1.0000052)]]\n6 [3.0994415e-06, 1.0000004, [(3.0994415e-06, 1.0000004)]]\n7 [0.0, 1.0, [(0.0, 1.0)]]\n8 [0.0, 1.0, [(0.0, 1.0)]]\n9 [0.0, 1.0, [(0.0, 1.0)]]\n10 [0.0, 1.0, [(0.0, 1.0)]]\n...\n90 [0.0, 1.0, [(0.0, 1.0)]]\n91 [0.0, 1.0, [(0.0, 1.0)]]\n92 [0.0, 1.0, [(0.0, 1.0)]]\n93 [0.0, 1.0, [(0.0, 1.0)]]\n94 [0.0, 1.0, [(0.0, 1.0)]]\n95 [0.0, 1.0, [(0.0, 1.0)]]\n96 [0.0, 1.0, [(0.0, 1.0)]]\n97 [0.0, 1.0, [(0.0, 1.0)]]\n98 [0.0, 1.0, [(0.0, 1.0)]]\n99 [0.0, 1.0, [(0.0, 1.0)]]</code></pre></div>","frontmatter":{"title":"Linear Regression 의 cost 최소화의 TensorFlow 구현","date":"January 04, 2019","thumbnail":null}}},"pageContext":{"slug":"/MachineLearning/2019-01-04-BasicChapter4_2/","previous":{"fields":{"slug":"/MachineLearning/2019-01-02-BasicChapter4_1/"},"frontmatter":{"title":"Linear Regression의 cost 최소화 알고리즘의 원리","category":"Machine Learning","draft":false}},"next":{"fields":{"slug":"/MachineLearning/2019-01-05-BasicChapter5_2/"},"frontmatter":{"title":"lab:multi-variable linear regression을 TensorFlow에서 구현하기","category":"Machine Learning","draft":false}}}},"staticQueryHashes":["3001444076","3128451518"]}