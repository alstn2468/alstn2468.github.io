{"componentChunkName":"component---src-templates-blog-post-js","path":"/MachineLearning/2019-05-29-BasicChapter11-3","result":{"data":{"site":{"siteMetadata":{"title":"Minsu's Dev Log","author":"Minsu Kim","siteUrl":"https://alstn2468.github.io","comment":{"disqusShortName":"","utterances":"alstn2468/alstn2468.github.io"},"sponsor":{"buyMeACoffeeId":"eMLdEwU"}}},"markdownRemark":{"id":"2fab71db-a357-5977-87cb-f34c8d76e201","excerpt":"해당 게시물은 Edwith에서 제공하는\n머신러닝과 딥러닝 BASIC을 듣고 요약 정리한 글입니다. Overfitting Training Set에 대해서 높은 정확도를 갖는다.\nTest Set에 대해서는 낮은 정확도를 갖는다.\nOverfitting된 모델은 실제로 사용 불가능하다. Overfitting을 방지하는 법 더 많은 학습 데이터 Feature의 갯수를 줄인다. 정규화(Regularization) 정규화 (Regularization) Weight값이 너무 크지 않도록 조절 L…","html":"<p>해당 게시물은 <a href=\"https://www.edwith.org\">Edwith</a>에서 제공하는<br/>\n<a href=\"https://www.edwith.org/others26/joinLectures/9829\">머신러닝과 딥러닝 BASIC</a>을 듣고 요약 정리한 글입니다.</p>\n<h2 id=\"overfitting\" style=\"position:relative;\"><a href=\"#overfitting\" aria-label=\"overfitting permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Overfitting</h2>\n<p><strong>Training Set</strong>에 대해서 <strong>높은 정확도</strong>를 갖는다.<br/>\n<strong>Test Set</strong>에 대해서는 <strong>낮은 정확도</strong>를 갖는다.<br/>\n<strong>Overfitting</strong>된 모델은 실제로 사용 불가능하다.<br/></p>\n<h2 id=\"overfitting을-방지하는-법\" style=\"position:relative;\"><a href=\"#overfitting%EC%9D%84-%EB%B0%A9%EC%A7%80%ED%95%98%EB%8A%94-%EB%B2%95\" aria-label=\"overfitting을 방지하는 법 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Overfitting을 방지하는 법</h2>\n<ul>\n<li>더 많은 학습 데이터</li>\n<li><strong>Feature</strong>의 갯수를 줄인다.</li>\n<li><strong>정규화(Regularization)</strong></li>\n</ul>\n<h2 id=\"정규화-regularization\" style=\"position:relative;\"><a href=\"#%EC%A0%95%EA%B7%9C%ED%99%94-regularization\" aria-label=\"정규화 regularization permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>정규화 (Regularization)</h2>\n<p><strong>Weight</strong>값이 너무 크지 않도록 조절<br/></p>\n<h2 id=\"l2-regularization\" style=\"position:relative;\"><a href=\"#l2-regularization\" aria-label=\"l2 regularization permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>L2 Regularization</h2>\n<p><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>c</mi><mi>o</mi><mi>s</mi><mi>t</mi><mo>+</mo><mi>λ</mi><mo>∑</mo><msup><mi>W</mi><mn>2</mn></msup></mrow><annotation encoding=\"application/x-tex\">cost + \\lambda \\sum W^{2}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.6984em;vertical-align:-0.0833em;\"></span><span class=\"mord mathnormal\">cos</span><span class=\"mord mathnormal\">t</span><span class=\"mspace\" style=\"margin-right:0.2222em;\"></span><span class=\"mbin\">+</span><span class=\"mspace\" style=\"margin-right:0.2222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1.0641em;vertical-align:-0.25em;\"></span><span class=\"mord mathnormal\">λ</span><span class=\"mspace\" style=\"margin-right:0.1667em;\"></span><span class=\"mop op-symbol small-op\" style=\"position:relative;top:0em;\">∑</span><span class=\"mspace\" style=\"margin-right:0.1667em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.13889em;\">W</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.8141em;\"><span style=\"top:-3.063em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mtight\">2</span></span></span></span></span></span></span></span></span></span></span></span></p>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\">l2reg <span class=\"token operator\">=</span> <span class=\"token number\">0.001</span> <span class=\"token operator\">*</span> tf<span class=\"token punctuation\">.</span>reduce_sum<span class=\"token punctuation\">(</span>tf<span class=\"token punctuation\">.</span>square<span class=\"token punctuation\">(</span>W<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span></code></pre></div>\n<h2 id=\"dropout\" style=\"position:relative;\"><a href=\"#dropout\" aria-label=\"dropout permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Dropout</h2>\n<p>연결된 <strong>Neural Network</strong>에서 데이터를<br/>\n학습할때 몇개의 <strong>노드의 연결을 끊는</strong> 방법</p>\n<p>아래와 같은 코드로 <strong>Dropout</strong> 사용 가능</p>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\">dropout_rate <span class=\"token operator\">=</span> tf<span class=\"token punctuation\">.</span>placeholder<span class=\"token punctuation\">(</span><span class=\"token string\">\"float\"</span><span class=\"token punctuation\">)</span>\n_L1 <span class=\"token operator\">=</span> tf<span class=\"token punctuation\">.</span>nn<span class=\"token punctuation\">.</span>relu<span class=\"token punctuation\">(</span>tf<span class=\"token punctuation\">.</span>add<span class=\"token punctuation\">(</span>tf<span class=\"token punctuation\">.</span>matmul<span class=\"token punctuation\">(</span>X<span class=\"token punctuation\">,</span> W1<span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span> B1<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\nL1 <span class=\"token operator\">=</span> tf<span class=\"token punctuation\">.</span>nn<span class=\"token punctuation\">.</span>dropout<span class=\"token punctuation\">(</span>_L1<span class=\"token punctuation\">,</span> dropout_rate<span class=\"token punctuation\">)</span></code></pre></div>\n<h2 id=\"train\" style=\"position:relative;\"><a href=\"#train\" aria-label=\"train permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Train</h2>\n<p>학습시에는 아래와 같이 <code class=\"language-text\">feed_dixt</code>에 <code class=\"language-text\">dropout_rate</code>를 지정해서 사용</p>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\">sess<span class=\"token punctuation\">.</span>run<span class=\"token punctuation\">(</span>\n    optimizer<span class=\"token punctuation\">,</span>\n    feed_dict<span class=\"token operator\">=</span><span class=\"token punctuation\">{</span>\n        X<span class=\"token punctuation\">:</span> batch_xs<span class=\"token punctuation\">,</span>\n        Y<span class=\"token punctuation\">:</span> batch_ys<span class=\"token punctuation\">,</span>\n        dropout_rate<span class=\"token punctuation\">:</span> <span class=\"token number\">0.7</span>\n    <span class=\"token punctuation\">}</span>\n<span class=\"token punctuation\">)</span></code></pre></div>\n<h2 id=\"evaluation\" style=\"position:relative;\"><a href=\"#evaluation\" aria-label=\"evaluation permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Evaluation</h2>\n<p>평가시에는 <code class=\"language-text\">dropout_rate</code>를 1로 지정해 사용</p>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string\">\"Accuracy : \"</span><span class=\"token punctuation\">,</span>\n      accuracy<span class=\"token punctuation\">.</span><span class=\"token builtin\">eval</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">{</span>\n          X<span class=\"token punctuation\">:</span> mnist<span class=\"token punctuation\">.</span>test<span class=\"token punctuation\">.</span>images<span class=\"token punctuation\">,</span>\n          Y<span class=\"token punctuation\">:</span> mnist<span class=\"token punctuation\">.</span>test<span class=\"token punctuation\">.</span>labels<span class=\"token punctuation\">,</span>\n          dropout_rate<span class=\"token punctuation\">:</span> <span class=\"token number\">1</span>\n      <span class=\"token punctuation\">}</span><span class=\"token punctuation\">)</span>\n<span class=\"token punctuation\">)</span></code></pre></div>\n<h2 id=\"ensemble-앙상블\" style=\"position:relative;\"><a href=\"#ensemble-%EC%95%99%EC%83%81%EB%B8%94\" aria-label=\"ensemble 앙상블 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Ensemble (앙상블)</h2>\n<p>실제 데이터에 대해 좋은 결과를 낸다는 뜻이다.<br/>\n데이터가 많고, 컴퓨터도 많다면 <strong>앙상블(ensemble)</strong> 사용 가능<br/>\n데이터를 <strong>여러 개</strong>의 Training Set으로 <strong>나누어</strong>서 <strong>동시에 학습을 진행</strong>해서,<br/>\n모든 training set에 대한 <strong>학습이 끝나면 결과를 통합</strong>하는 방법이다.<br/>\n앙상블을 사용하면 <strong>최소 2%에서 4~5%까지의 성능이 향상</strong>이 가능하다.<br/>\n여러 번의 시도를 거쳐 <strong>균형 잡힌 결과를 도출하</strong>기 때문에 점에서 dropout과 비슷한 부분이 있다.<br/></p>","frontmatter":{"title":"Dropout 과 앙상블","date":"May 29, 2019","thumbnail":null}}},"pageContext":{"slug":"/MachineLearning/2019-05-29-BasicChapter11-3/","previous":{"fields":{"slug":"/MachineLearning/2019-05-23-BasicChapter11-1/"},"frontmatter":{"title":"XSigmoid 보다 ReLU가 더 좋아","category":"Machine Learning","draft":false}},"next":{"fields":{"slug":"/MachineLearning/2019-06-01-BasicChapter11-4/"},"frontmatter":{"title":"레고처럼 넷트웍 모듈을 마음껏 쌓아 보자","category":"Machine Learning","draft":false}}}},"staticQueryHashes":["3001444076","3128451518"]}