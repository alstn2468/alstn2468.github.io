{"componentChunkName":"component---src-templates-blog-post-js","path":"/MachineLearning/2019-05-04-BasicChapter8-4","result":{"data":{"site":{"siteMetadata":{"title":"Minsu's Dev Log","author":"Minsu Kim","siteUrl":"https://alstn2468.github.io","comment":{"disqusShortName":"","utterances":"alstn2468/alstn2468.github.io"},"sponsor":{"buyMeACoffeeId":"eMLdEwU"}}},"markdownRemark":{"id":"98bbbaa9-1b21-5953-96a9-03efca69f922","excerpt":"해당 게시물은 Edwith에서 제공하는\n머신러닝과 딥러닝 BASIC을 듣고 요약 정리한 글입니다. MNIST Dataset 손으로 숫자를 글씨 정보를 갖고있는 데이터 셋\n우체국에서 손으로 작성한 글씨를 판별하기 위해 만든 데이터 셋 28 X 28 X I image 데이터 셋으로\n784(28 * 28)개의 X데이터를 갖고 Y데이터는 0 ~ 9 사이의 숫자를 갖는다. Softmax Training epoch/batch 한번에 몇개씩 학습시킬시 결정하는 것이 batch size…","html":"<p>해당 게시물은 <a href=\"https://www.edwith.org\">Edwith</a>에서 제공하는<br/>\n<a href=\"https://www.edwith.org/others26/joinLectures/9829\">머신러닝과 딥러닝 BASIC</a>을 듣고 요약 정리한 글입니다.</p>\n<h2 id=\"mnist-dataset\" style=\"position:relative;\"><a href=\"#mnist-dataset\" aria-label=\"mnist dataset permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>MNIST Dataset</h2>\n<p>손으로 숫자를 글씨 정보를 갖고있는 데이터 셋<br/>\n우체국에서 손으로 작성한 글씨를 판별하기 위해 만든 데이터 셋</p>\n<p>28 X 28 X I image 데이터 셋으로<br/>\n<strong>784(28 * 28)</strong>개의 <strong>X데이터</strong>를 갖고 <strong>Y데이터</strong>는 <strong>0 ~ 9 사이의 숫자</strong>를 갖는다.<br/></p>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token keyword\">import</span> tensorflow <span class=\"token keyword\">as</span> tf\n<span class=\"token keyword\">import</span> matplotlib<span class=\"token punctuation\">.</span>pyplot <span class=\"token keyword\">as</span> plt\n<span class=\"token keyword\">import</span> random\n<span class=\"token keyword\">from</span> tensorflow<span class=\"token punctuation\">.</span>examples<span class=\"token punctuation\">.</span>tutorials<span class=\"token punctuation\">.</span>mnist <span class=\"token keyword\">import</span> input_data\n\n<span class=\"token comment\"># Check out https://www.tensorflow.org/get_started/mnist/beginners for</span>\n<span class=\"token comment\"># more information about the mnist dataset</span>\nmnist <span class=\"token operator\">=</span> input_data<span class=\"token punctuation\">.</span>read_data_sets<span class=\"token punctuation\">(</span><span class=\"token string\">\"MNIST_data/\"</span><span class=\"token punctuation\">,</span> one_hot<span class=\"token operator\">=</span><span class=\"token boolean\">True</span><span class=\"token punctuation\">)</span>\n\nnb_classes <span class=\"token operator\">=</span> <span class=\"token number\">10</span>\n\n<span class=\"token comment\"># MNIST data image of shape 28 * 28 = 784</span>\nX <span class=\"token operator\">=</span> tf<span class=\"token punctuation\">.</span>placeholder<span class=\"token punctuation\">(</span>tf<span class=\"token punctuation\">.</span>float32<span class=\"token punctuation\">,</span> <span class=\"token punctuation\">[</span><span class=\"token boolean\">None</span><span class=\"token punctuation\">,</span> <span class=\"token number\">784</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span>\n<span class=\"token comment\"># 0 ~ 9 digits recognition = 10 classes</span>\nY <span class=\"token operator\">=</span> tf<span class=\"token punctuation\">.</span>placeholder<span class=\"token punctuation\">(</span>tf<span class=\"token punctuation\">.</span>float32<span class=\"token punctuation\">,</span> <span class=\"token punctuation\">[</span><span class=\"token boolean\">None</span><span class=\"token punctuation\">,</span> nb_classes<span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span>\n\nW <span class=\"token operator\">=</span> tf<span class=\"token punctuation\">.</span>Variable<span class=\"token punctuation\">(</span>tf<span class=\"token punctuation\">.</span>random_normal<span class=\"token punctuation\">(</span><span class=\"token punctuation\">[</span><span class=\"token number\">784</span><span class=\"token punctuation\">,</span> nb_classes<span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\nb <span class=\"token operator\">=</span> tf<span class=\"token punctuation\">.</span>Variable<span class=\"token punctuation\">(</span>tf<span class=\"token punctuation\">.</span>random_normal<span class=\"token punctuation\">(</span><span class=\"token punctuation\">[</span>nb_classes<span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span></code></pre></div>\n<h2 id=\"softmax\" style=\"position:relative;\"><a href=\"#softmax\" aria-label=\"softmax permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Softmax</h2>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token comment\"># Hypothesis (using softmax)</span>\nhypothesis <span class=\"token operator\">=</span> tf<span class=\"token punctuation\">.</span>nn<span class=\"token punctuation\">.</span>softmax<span class=\"token punctuation\">(</span>tf<span class=\"token punctuation\">.</span>matmul<span class=\"token punctuation\">(</span>X<span class=\"token punctuation\">,</span> W<span class=\"token punctuation\">)</span> <span class=\"token operator\">+</span> b<span class=\"token punctuation\">)</span>\n\ncost <span class=\"token operator\">=</span> tf<span class=\"token punctuation\">.</span>reduce_mean<span class=\"token punctuation\">(</span><span class=\"token operator\">-</span>tf<span class=\"token punctuation\">.</span>reduce_sum<span class=\"token punctuation\">(</span>Y <span class=\"token operator\">*</span> tf<span class=\"token punctuation\">.</span>log<span class=\"token punctuation\">(</span>hypothesis<span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span> axis<span class=\"token operator\">=</span><span class=\"token number\">1</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\noptimzer <span class=\"token operator\">=</span> tf<span class=\"token punctuation\">.</span>train<span class=\"token punctuation\">.</span>GradientDescentOptimizer<span class=\"token punctuation\">(</span>learning_rate<span class=\"token operator\">=</span><span class=\"token number\">0.1</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span>minimize<span class=\"token punctuation\">(</span>cost<span class=\"token punctuation\">)</span>\n\n<span class=\"token comment\"># Test model</span>\nis_correct <span class=\"token operator\">=</span> tf<span class=\"token punctuation\">.</span>equal<span class=\"token punctuation\">(</span>tf<span class=\"token punctuation\">.</span>argmax<span class=\"token punctuation\">(</span>hypothesis<span class=\"token punctuation\">,</span> <span class=\"token number\">1</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span> tf<span class=\"token punctuation\">.</span>argmax<span class=\"token punctuation\">(</span>Y<span class=\"token punctuation\">,</span> <span class=\"token number\">1</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n<span class=\"token comment\"># Calculate accuracy</span>\naccuracy <span class=\"token operator\">=</span> tf<span class=\"token punctuation\">.</span>reduce_mean<span class=\"token punctuation\">(</span>tf<span class=\"token punctuation\">.</span>cast<span class=\"token punctuation\">(</span>is_correct<span class=\"token punctuation\">,</span> tf<span class=\"token punctuation\">.</span>float32<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span></code></pre></div>\n<h2 id=\"training-epochbatch\" style=\"position:relative;\"><a href=\"#training-epochbatch\" aria-label=\"training epochbatch permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Training epoch/batch</h2>\n<p>한번에 몇개씩 학습시킬시 결정하는 것이 <strong>batch size</strong><br/>\n전체 데이터 셋을 한 번 다 도는 것을 <strong>1epoch</strong> 라고 한다.</p>\n<p>예를 들어 <strong>1000</strong>개의 <strong>Data Set</strong>이 있을 경우<br/>\n<strong>Batch size</strong>가 <strong>500</strong>일 경우 <strong>2번의 반복</strong>으로 <strong>1번의 epoch</strong>가 완료된다.</p>\n<p>따라서 아래의 코드는 <strong>epoch</strong> <code class=\"language-text\">15</code>이고<br/>\n<strong>batch siz</strong>e가 <code class=\"language-text\">100</code>이므로<br/>\n밖의 for문에서 <strong>15</strong>번의 반복이 일어나고<br/>\n안쪽 for문에서 <strong>데이터의 개수 / 100</strong> 만큼의 반복이 일어나며<br/>\n<strong>100개의 데이터</strong>씩 학습시키고 <strong>안쪽 루프</strong>가 끝나면 <strong>1epoch</strong>이 종료된다.<br/></p>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token comment\"># parameters</span>\nnum_epochs <span class=\"token operator\">=</span> <span class=\"token number\">15</span>\nbatch_size <span class=\"token operator\">=</span> <span class=\"token number\">100</span>\nnum_iterations <span class=\"token operator\">=</span> <span class=\"token builtin\">int</span><span class=\"token punctuation\">(</span>mnist<span class=\"token punctuation\">.</span>train<span class=\"token punctuation\">.</span>num_examples <span class=\"token operator\">/</span> batch_size<span class=\"token punctuation\">)</span>\n\n<span class=\"token keyword\">with</span> tf<span class=\"token punctuation\">.</span>Session<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span> <span class=\"token keyword\">as</span> sess<span class=\"token punctuation\">:</span>\n    <span class=\"token comment\"># Initialize TensorFlow variables</span>\n    sess<span class=\"token punctuation\">.</span>run<span class=\"token punctuation\">(</span>tf<span class=\"token punctuation\">.</span>global_variables_initializer<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n    <span class=\"token comment\"># Training cycle</span>\n    <span class=\"token keyword\">for</span> epoch <span class=\"token keyword\">in</span> <span class=\"token builtin\">range</span><span class=\"token punctuation\">(</span>num_epochs<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n        avg_cost <span class=\"token operator\">=</span> <span class=\"token number\">0</span>\n\n        <span class=\"token keyword\">for</span> i <span class=\"token keyword\">in</span> <span class=\"token builtin\">range</span><span class=\"token punctuation\">(</span>num_iterations<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n            batch_xs<span class=\"token punctuation\">,</span> batch_ys <span class=\"token operator\">=</span> mnist<span class=\"token punctuation\">.</span>train<span class=\"token punctuation\">.</span>next_batch<span class=\"token punctuation\">(</span>batch_size<span class=\"token punctuation\">)</span>\n            _<span class=\"token punctuation\">,</span> cost_val <span class=\"token operator\">=</span> sess<span class=\"token punctuation\">.</span>run<span class=\"token punctuation\">(</span><span class=\"token punctuation\">[</span>optimzer<span class=\"token punctuation\">,</span> cost<span class=\"token punctuation\">]</span><span class=\"token punctuation\">,</span> feed_dict<span class=\"token operator\">=</span><span class=\"token punctuation\">{</span>X<span class=\"token punctuation\">:</span> batch_xs<span class=\"token punctuation\">,</span> Y<span class=\"token punctuation\">:</span> batch_ys<span class=\"token punctuation\">}</span><span class=\"token punctuation\">)</span>\n            avg_cost <span class=\"token operator\">+=</span> cost_val <span class=\"token operator\">/</span> num_iterations\n\n        <span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string\">\"Epoch: {:04d}, Cost: {:.9f}\"</span><span class=\"token punctuation\">.</span><span class=\"token builtin\">format</span><span class=\"token punctuation\">(</span>epoch <span class=\"token operator\">+</span> <span class=\"token number\">1</span><span class=\"token punctuation\">,</span> avg_cost<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n\n    <span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string\">\"Learning finished\"</span><span class=\"token punctuation\">)</span>\n\n    <span class=\"token comment\"># Test the model using test sets</span>\n    <span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span>\n        <span class=\"token string\">\"Accuracy: \"</span><span class=\"token punctuation\">,</span>\n        accuracy<span class=\"token punctuation\">.</span><span class=\"token builtin\">eval</span><span class=\"token punctuation\">(</span>\n            session<span class=\"token operator\">=</span>sess<span class=\"token punctuation\">,</span> feed_dict<span class=\"token operator\">=</span><span class=\"token punctuation\">{</span>X<span class=\"token punctuation\">:</span> mnist<span class=\"token punctuation\">.</span>test<span class=\"token punctuation\">.</span>images<span class=\"token punctuation\">,</span> Y<span class=\"token punctuation\">:</span> mnist<span class=\"token punctuation\">.</span>test<span class=\"token punctuation\">.</span>labels<span class=\"token punctuation\">}</span>\n        <span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span>\n    <span class=\"token punctuation\">)</span>\n\n    <span class=\"token comment\"># Sample image show and prediction</span>\n    <span class=\"token comment\"># Get one and predict</span>\n    r <span class=\"token operator\">=</span> random<span class=\"token punctuation\">.</span>randint<span class=\"token punctuation\">(</span><span class=\"token number\">0</span><span class=\"token punctuation\">,</span> mnist<span class=\"token punctuation\">.</span>test<span class=\"token punctuation\">.</span>num_examples <span class=\"token operator\">-</span> <span class=\"token number\">1</span><span class=\"token punctuation\">)</span>\n    <span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string\">\"Label: \"</span><span class=\"token punctuation\">,</span> sess<span class=\"token punctuation\">.</span>run<span class=\"token punctuation\">(</span>tf<span class=\"token punctuation\">.</span>argmax<span class=\"token punctuation\">(</span>mnist<span class=\"token punctuation\">.</span>test<span class=\"token punctuation\">.</span>labels<span class=\"token punctuation\">[</span>r <span class=\"token punctuation\">:</span> r <span class=\"token operator\">+</span> <span class=\"token number\">1</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">,</span> <span class=\"token number\">1</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n    <span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span>\n        <span class=\"token string\">\"Prediction: \"</span><span class=\"token punctuation\">,</span>\n        sess<span class=\"token punctuation\">.</span>run<span class=\"token punctuation\">(</span>tf<span class=\"token punctuation\">.</span>argmax<span class=\"token punctuation\">(</span>hypothesis<span class=\"token punctuation\">,</span> <span class=\"token number\">1</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span> feed_dict<span class=\"token operator\">=</span><span class=\"token punctuation\">{</span>X<span class=\"token punctuation\">:</span> mnist<span class=\"token punctuation\">.</span>test<span class=\"token punctuation\">.</span>images<span class=\"token punctuation\">[</span>r <span class=\"token punctuation\">:</span> r <span class=\"token operator\">+</span> <span class=\"token number\">1</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">}</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span>\n    <span class=\"token punctuation\">)</span>\n\n    plt<span class=\"token punctuation\">.</span>imshow<span class=\"token punctuation\">(</span>\n        mnist<span class=\"token punctuation\">.</span>test<span class=\"token punctuation\">.</span>images<span class=\"token punctuation\">[</span>r <span class=\"token punctuation\">:</span> r <span class=\"token operator\">+</span> <span class=\"token number\">1</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">.</span>reshape<span class=\"token punctuation\">(</span><span class=\"token number\">28</span><span class=\"token punctuation\">,</span> <span class=\"token number\">28</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span>\n        cmap<span class=\"token operator\">=</span><span class=\"token string\">\"Greys\"</span><span class=\"token punctuation\">,</span>\n        interpolation<span class=\"token operator\">=</span><span class=\"token string\">\"nearest\"</span><span class=\"token punctuation\">,</span>\n    <span class=\"token punctuation\">)</span>\n    plt<span class=\"token punctuation\">.</span>show<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span></code></pre></div>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">Epoch: 0001, Cost: 2.697827901\nEpoch: 0002, Cost: 1.077157190\nEpoch: 0003, Cost: 0.864903082\nEpoch: 0004, Cost: 0.759544095\nEpoch: 0005, Cost: 0.692458839\nEpoch: 0006, Cost: 0.643773215\nEpoch: 0007, Cost: 0.606989562\nEpoch: 0008, Cost: 0.577427680\nEpoch: 0009, Cost: 0.552740937\nEpoch: 0010, Cost: 0.532466000\nEpoch: 0011, Cost: 0.515204259\nEpoch: 0012, Cost: 0.499481865\nEpoch: 0013, Cost: 0.486141274\nEpoch: 0014, Cost: 0.473691142\nEpoch: 0015, Cost: 0.463160439\nLearning finished\nAccuracy:  0.8924\nLabel:  [8]\nPrediction:  [8]</code></pre></div>\n<span class=\"gatsby-resp-image-wrapper\" style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 255px; \">\n      <span class=\"gatsby-resp-image-background-image\" style=\"padding-bottom: 98.66666666666666%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAUCAYAAACNiR0NAAAACXBIWXMAAAsSAAALEgHS3X78AAADKElEQVQ4y5VUS0hbQRSdpgiW1NBKk7oShbSJjUkINqWN/YDiIqW4cCHo1oUuFEQQURT8giC4EcEvKCoKKuIH1IUf8LNSFFQQXCiIC11JmvhN3umd6ZvHM7EtvXDJfZOZM+fee+YyxpjB7/e/XFxc/LiyspK5vLzs+19fXV31LSwsfO7t7U1gAFhtbe2nYDAYikQiuL+//6vf3t5qfnd3J9b4uUAggK2tLR/r6upim5ub1uvr65/4bRFyJdqlPbbOz9B57O7u+gRDAnVfXV0JQPo/oj/MjRhoAOfn58JPTk6UUCgk1yN0Hjs7Oz7Gramp6YNkqAJCjSFtb28PdXV1sNlscLlcMJvNaGxsRAxgQ0MDo2a8oYWgBIwGa2lpEQAejwf19fXo6+tDTk4OvF4vr50AJLYaQ8Pg4GD6Ywx50SsrK2E0GtHW1gZeJ26np6dITU1FSUmJxlAPaOEp39zcBCRgOBwWB7e3t2EwGNDe3q6xPTg4QEpKCrKysnB2dhabclVVFVtaWnqrT5nLgNvx8TGsVisKCwtBF2J/fx92ux0FBQWQe+jyh4C8y2NjY+/0gDxlyXJ+fh7x8fGiZk6nE8XFxUKDKhikbPRdfk1F9+pT1jdkbW0NiYmJoH3Iz8/X1uWFMYCTk5OMWNj0OhTqppRaW1vhdruRm5sLk8mE5uZmPTPpsSlPTEykyS7LAnZ2diIpKQkbGxsgIYuu0hPV9PlHQDJzRUXFV33K/LeoqAh5eXkC4OLiAsnJyaipqYFkrxP/Q8C5uTk2MzNjl02RDEdGRmCxWFBeXg5Sgqjh1NTUvwGHhoY4aHQNFS4HempKXFycQmAKgWpvOtqiU35VXV2dSVIIqA1U9F2mTVhfX9e+H3nn4hIOqE2b8fHxNM6QpyI7KOefOs7kunhFqmTC/FfdE6Z5yudhJnM4HCw7OzuBUvpCUzedRtl7SvUbxY7u7u4Mas73gYEBZ39/v6esrMw/OjrqJlW46B3/6OnpyZienk4vLS31d3R0eOn7GVPtKR8SxFQwJnsyPDwsY9Ps7KyMjZeXl+zw8JDHL/ja0dERj5/zmNTCfgE9ZdSUniH9ZQAAAABJRU5ErkJggg=='); background-size: cover; display: block;\"></span>\n  <img class=\"gatsby-resp-image-image\" alt=\"1\" title=\"1\" src=\"/static/c2edd11fea71c45b5b48aea502824cb4/b8c8f/1.png\" srcset=\"/static/c2edd11fea71c45b5b48aea502824cb4/8a4e8/1.png 150w,\n/static/c2edd11fea71c45b5b48aea502824cb4/b8c8f/1.png 255w\" sizes=\"(max-width: 255px) 100vw, 255px\" style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\" loading=\"lazy\">\n    </span>","frontmatter":{"title":"lab:Meet MNIST Dataset","date":"May 04, 2019","thumbnail":null}}},"pageContext":{"slug":"/MachineLearning/2019-05-04-BasicChapter8-4/","previous":{"fields":{"slug":"/MachineLearning/2019-05-02-BasicChapter8-3/"},"frontmatter":{"title":"lab:training/test dataset, learning rate, normalization","category":"Machine Learning","draft":false}},"next":{"fields":{"slug":"/MachineLearning/2019-05-12-BasicChapter9-1/"},"frontmatter":{"title":"딥러닝의 시작과 XOR 문제","category":"Machine Learning","draft":false}}}},"staticQueryHashes":["3001444076","3128451518"]}